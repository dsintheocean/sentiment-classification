# Проект оценки токсичности комментариев

## Описание проекта
Необходимо создать инструмент для оценки токсичности комментария, чтобы при необходимости отправлять их автоматически на модерацию.  
Задача - обучить модель классифицировать комментарии на позитивные и негативные.  
Имеется набор данных с разметкой о токсичности.  

## Основные выводы
Решена задача бинарной классификации с обработкой естественного языка.  
Проведена токенизация с помощью Spacy, очистка с помощью re.  
Сформированы фичи из исходного текста с помощью векторизатора TF_IDF.  
Достигнуто целевое значение f1-меры = 0.74 с помощью модели CatBoost.  

## Доп. информация 
Основные инструменты: Pandas, re, Spacy, tf-idf, Python, Data Preprocessing, CatBoost, Scikit-learn.
